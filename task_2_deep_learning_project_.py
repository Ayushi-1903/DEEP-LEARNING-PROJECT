# -*- coding: utf-8 -*-
"""Task 2 Deep Learning Project .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/194UxZo8NYVf2R1qkL8Xpfh8EkUP_Woq5

# Name : AYUSHI VERMA

üì¶ Import Libraries
Loads required libraries like TensorFlow, NumPy, Matplotlib, etc. for image processing and model training.
"""

import pandas as pd
import numpy as np
import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

"""üå∏ Load Dataset:
Loads the 'tf_flowers' dataset from TensorFlow Datasets and splits it into training and test sets.
"""

(dataset_train, dataset_test), dataset_info = tfds.load(
    'tf_flowers',
    split=['train[:80%]', 'train[80%:]'],
    with_info=True,
    as_supervised=True
)

print("Classes:", dataset_info.features['label'].names)

"""Compute Channel Statistics:
Resizes images and calculates mean and standard deviation per color channel for normalization.
"""

IMG_SIZE = 128  # Or any other desired size
all_images = []
for img, _ in dataset_train:
    all_images.append(tf.image.resize(img, (IMG_SIZE, IMG_SIZE)).numpy())

all_images = np.stack(all_images)
channel_means = all_images.mean(axis=(0, 1, 2)) / 255.0
channel_stds = all_images.std(axis=(0, 1, 2)) / 255.0

print("Channel Means:", channel_means)
print("Channel STDs:", channel_stds)

"""üñºÔ∏è Resize and Store Train Images:
Resizes training images to uniform size and stores them along with labels as NumPy arrays.


"""

train_images = []
train_labels = []
for image, label in dataset_train:
    resized_image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))
    train_images.append(resized_image.numpy())
    train_labels.append(label.numpy())

train_images = np.array(train_images)
train_labels = np.array(train_labels)

print(f"train_images shape: {train_images.shape}")
print(f"train_labels shape: {train_labels.shape}")

"""üìä Plot Pixel Distributions: Plots histograms of pixel values per RGB channel before normalization to visualize distribution."""

# Plot per-channel pixel value distributions
colors = ['r', 'g', 'b']
plt.figure(figsize=(10, 4))
for i, color in enumerate(colors):
    if train_images.ndim == 4:  # Expecting (num_samples, height, width, channels)
        plt.hist(train_images[:, :, :, i].flatten(), bins=50, color=color, alpha=0.6, label=f'{color.upper()} channel')
    else:
        print("Error: train_images does not have the expected dimensions for plotting.")
plt.title("Pixel Value Distribution per Channel (Before Normalization)")
plt.xlabel("Pixel value")
plt.ylabel("Frequency")
plt.legend()
plt.show()

"""üß™ Resize and Store Test Images:
Processes test images similarly for evaluation purposes.
"""

test_images = []
test_labels = []
for image, label in dataset_test:
    resized_image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))
    test_images.append(resized_image.numpy())
    test_labels.append(label.numpy())

test_images = np.array(test_images)
test_labels = np.array(test_labels)

# Now you can normalize test_images
x_train = (train_images / 255.0 - channel_means) / channel_stds
x_test = (test_images / 255.0 - channel_means) / channel_stds

"""üîÑ Data Augmentation:
Defines a sequential augmentation pipeline (flip, rotation, zoom) to artificially expand the training data.

üëÄ Display Original & Augmented Images:
Plots original and augmented versions of sample images for visual comparison.
"""

data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
])

num_images = 5
sample_images = train_images[:num_images]

plt.figure(figsize=(10, 4 * num_images))

for i in range(num_images):
    # De-normalize the image
    image = sample_images[i] / 255.0
    image = image * channel_stds + channel_means
    image = np.clip(image * 255.0, 0, 255).astype(np.uint8)

    plt.subplot(num_images, 2, 2 * i + 1)
    plt.imshow(image)
    plt.title("Original")
    plt.axis("off")

plt.tight_layout()
plt.show()

img_tensor = tf.convert_to_tensor(sample_images[i])
aug_img = data_augmentation(img_tensor, training=True)

# De-normalize augmented image
denorm_img = (aug_img.numpy() * channel_stds + channel_means) * 255.0
denorm_img = np.clip(denorm_img, 0, 255).astype(np.uint8)

plt.subplot(num_images, 2, 2 * i + 2)
plt.imshow(denorm_img)
plt.title("Augmented")
plt.axis("off")

plt.tight_layout()
plt.show()

batch_size = 64
train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))
train_ds = train_ds.shuffle(10000).map(lambda x, y: (data_augmentation(x), y)).batch(batch_size).prefetch(tf.data.AUTOTUNE)

test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size)

class_names = ['dandelion', 'daisy', 'tulips', 'sunflowers', 'roses']

plt.figure(figsize=(10, 10))
for i in range(9):
    plt.subplot(3, 3, i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)

    # De-normalize the image for display
    image = train_images[i] / 255.0  # First normalize to [0,1]
    image = image * channel_stds + channel_means  # Un-normalize using stats
    image = np.clip(image * 255.0, 0, 255).astype(np.uint8)  # Rescale to [0,255]

    plt.imshow(image)
    flower_class_name = class_names[train_labels[i]]
    plt.xlabel(flower_class_name)  # Display the flower class name
plt.show()

"""üß† Define CNN Model:
Builds a sequential convolutional neural network for image classification.

‚öôÔ∏è Compile Model:
Sets the optimizer, loss function, and evaluation metric for model training.

üèãÔ∏è Train Model:
Trains the CNN on the training dataset and evaluates it on the validation (test) dataset.
"""

model = models.Sequential([
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)), # Use IMG_SIZE here
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(dataset_info.features['label'].num_classes) # Output layer with correct number of classes
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model.fit(train_images, train_labels, epochs=10,
                    validation_data=(test_images, test_labels))

"""üìà Plot Training History:
Visualizes training and validation accuracy and loss over epochs.
"""

plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Accuracy Over Epochs')

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Loss Over Epochs')

plt.show()

"""üß™ Evaluate Test Accuracy:
Evaluates the final model on test images and prints the accuracy.
"""

test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print(f'\nTest accuracy: {test_acc*100:.2f}%')

"""üìä Make Predictions:
Adds a Softmax layer and makes probability predictions on test images.
"""

probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])
predictions = probability_model.predict(test_images)

def plot_image(i, predictions_array, true_label, img):
    # Access the true label directly if it's a 1D array
    true_label, img = true_label[i], img[i]
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(img)

    predicted_label = np.argmax(predictions_array)
    if predicted_label == true_label:
        color = 'blue'
    else:
        color = 'red'

    plt.xlabel(f"Pred: {class_names[predicted_label]} ({100*np.max(predictions_array):.0f}%) \n True: {class_names[true_label]}", color=color)

plt.figure(figsize=(10,10))
for i in range(9):
    plt.subplot(3,3,i+1)
    plot_image(i, predictions[i], test_labels, test_images)
plt.show()
plt.figure(figsize=(10,10))
for i in range(9):
    plt.subplot(3,3,i+1)
    plot_image(i, predictions[i], test_labels, test_images)
plt.show()

def plot_image(i, predictions_array, true_label, img):
    true_label, img = true_label[i], img[i]
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])

    # De-normalize the image for display
    image = img / 255.0  # First normalize to [0,1]
    image = image * channel_stds + channel_means  # Un-normalize using stats
    image = np.clip(image * 255.0, 0, 255).astype(np.uint8)  # Rescale to [0,255]

    plt.imshow(image)  # Display the de-normalized image

    predicted_label = np.argmax(predictions_array)
    if predicted_label == true_label:
        color = 'blue'
    else:
        color = 'red'

    plt.xlabel(f"Pred: {class_names[predicted_label]} ({100*np.max(predictions_array):.0f}%) \n True: {class_names[true_label]}", color=color)

plt.figure(figsize=(10,10))
for i in range(9):
    plt.subplot(3,3,i+1)
    plot_image(i, predictions[i], test_labels, test_images)
plt.show()
plt.figure(figsize=(10,10))
for i in range(9):
    plt.subplot(3,3,i+1)
    plot_image(i, predictions[i], test_labels, test_images)
plt.show()

import IPython.display as display
from PIL import Image
import io
import numpy as np

# Select a few images from the validation (test) set
val_images = test_images[:6]  # First 6 test images

for i in range(6):
    # De-normalize the image for display
    image = val_images[i]
    image = image * channel_stds + channel_means  # Un-normalize using stats
    img_array = np.clip(image * 255.0, 0, 255).astype(np.uint8) # Rescale to [0,255]

    img = Image.fromarray(img_array)

    # Convert to PNG bytes
    with io.BytesIO() as output:
        img.save(output, format="PNG")
        image_data = output.getvalue()

    print(f"Image {i+1}")
    display.display(display.Image(data=image_data))

"""üéØ Final Test Set Visualization:
Predicts and plots true vs predicted labels on 10 test samples using color-coded titles.
"""

class_names = dataset_info.features['label'].names

for images, labels in test_ds.take(1):
    predictions = model.predict(images)
    predicted_labels = np.argmax(predictions, axis=1)

    plt.figure(figsize=(15, 8))
    for i in range(10):
        plt.subplot(2, 5, i+1)

        # De-normalize image
        img = images[i].numpy()
        img = (img * channel_stds + channel_means) * 255.0
        img = np.clip(img, 0, 255).astype(np.uint8)

        plt.imshow(img)

        true_label = class_names[labels[i].numpy()]
        pred_label = class_names[predicted_labels[i]]
        color = 'green' if true_label == pred_label else 'red'

        plt.title(f"True: {true_label}\nPred: {pred_label}", color=color)
        plt.axis('off')

    plt.show()

"""Implements transfer learning using MobileNetV2 (with frozen base), adds custom layers, and trains on flower dataset for 5 epochs."""

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

# Preprocess images for MobileNetV2
x_train_mobilenet = preprocess_input(train_images.copy())
x_test_mobilenet = preprocess_input(test_images.copy())

# Create model
base_model = MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3),
                         include_top=False,
                         weights='imagenet')

base_model.trainable = False  # Freeze base

model_transfer = tf.keras.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(dataset_info.features['label'].num_classes, activation='softmax')
])

model_transfer.compile(optimizer='adam',
                       loss='sparse_categorical_crossentropy',
                       metrics=['accuracy'])

history_transfer = model_transfer.fit(
    x_train_mobilenet, train_labels,
    validation_data=(x_test_mobilenet, test_labels),
    epochs=5
)

"""Generates and displays a confusion matrix heatmap and classification report to evaluate model performance on the test set."""

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# Predict on test set
y_pred = np.argmax(model.predict(test_images), axis=1)

# Confusion matrix
cm = confusion_matrix(test_labels, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.title('Confusion Matrix')
plt.show()

# Classification report
print(classification_report(test_labels, y_pred, target_names=class_names))

"""Calculates per-class accuracy, displays CNN layer outputs, predicts top-3 class probabilities for a test image, and visualizes the sample image by using t-SNE."""

from sklearn.manifold import TSNE

correct = np.zeros(len(class_names))
total = np.zeros(len(class_names))
for i in range(len(test_labels)):
    label = test_labels[i]
    pred = y_pred[i]
    if label == pred:
        correct[label] += 1
    total[label] += 1

print("\nPer-class Accuracy:")
for i in range(len(class_names)):
    acc = 100 * correct[i] / total[i]
    print(f"{class_names[i]}: {acc:.2f}%")

for i, layer in enumerate(model.layers):
    print(f"{i}: {layer.name} ‚Äî {layer.output.shape}")

# Predict Top-3 Labels
from tensorflow.keras.applications.imagenet_utils import decode_predictions
import matplotlib.pyplot as plt

sample_img = x_test[0:1]
probs = tf.nn.softmax(model.predict(sample_img)).numpy()[0]
top_3 = np.argsort(probs)[-3:][::-1]
print("Top-3 predictions:")
for i in top_3:
    print(f"{class_names[i]}: {probs[i]*100:.2f}%")

# Display the image if you want to see it (optional)
plt.imshow(sample_img[0])
plt.show()